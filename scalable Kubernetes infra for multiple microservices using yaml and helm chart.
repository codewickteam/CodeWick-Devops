To create a scalable Kubernetes infrastructure for multiple microservices using YAML and Helm charts:
step 1: Set up the Kubernetes cluster: Ensure you have a Kubernetes cluster ready to deploy your infrastructure. You can use a cloud provider like Google Kubernetes Engine (GKE), Amazon Elastic Kubernetes Service (EKS), or deploy your own cluster using tools like kops or kubeadm. (for sample purposes I have used minikube).

step 2: Prepare the YAML files: Create YAML files to define the Kubernetes resources needed for your microservices. This includes Deployment, Service, Ingress, ConfigMap, and Secret definitions.

	Deployment: Define the containers and their specifications, including image, ports, resources, and scaling rules.
	Service: Define a stable network endpoint for accessing your microservices.
	Ingress: Configure routing rules for incoming traffic to reach the appropriate microservices.
	ConfigMap: Store configuration data that can be accessed by your microservices.
	Secret: Store sensitive data, such as API keys or passwords, securely.  

step 3: Package the YAML files as Helm charts: Helm is a package manager for Kubernetes that simplifies deploying and managing applications. Create a Helm chart for each microservice to package the YAML files along with any necessary dependencies or configurations.

Initialize a Helm chart: Use the helm create command to generate a basic chart structure.
Customize the chart: Modify the generated files in the chart's directory, including the values.yaml file, which allows you to define configurable values for the deployment.
Add your YAML files: Place your microservice's YAML files in the appropriate locations within the chart.
Define dependencies: If your microservice relies on other services, specify these dependencies in the chart's requirements.yaml file.

step 4: eploy the Helm charts: Once your Helm charts are ready, you can deploy them to your Kubernetes cluster.

Install charts: Use the helm install command to install a chart, specifying the chart name and any necessary configuration overrides.
Manage releases: Helm manages deployments as "releases," allowing you to easily upgrade, rollback, or uninstall a release.

step 5: Monitor and scale your infrastructure: Implement monitoring and autoscaling to ensure your infrastructure is performing optimally.

Monitoring: Use tools like Prometheus and Grafana to collect and visualize metrics from your Kubernetes cluster and microservices.
Autoscaling: Configure Horizontal Pod Autoscaler (HPA) to automatically scale your microservices based on CPU or custom metrics.

here is an sample yaml file for kubernetes Deployment:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sample-microservice
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sample-microservice
  template:
    metadata:
      labels:
        app: sample-microservice
    spec:
      containers:
        - name: sample-microservice
          image: your-registry/sample-microservice:latest
          ports:
            - containerPort: 8080
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
This YAML file can be applied using the "kubectl apply -f <filename>" command to create the Deployment in your Kubernetes cluster. 

here is an sample yaml file for kubernetes Service:
apiVersion: v1
kind: Service
metadata:
  name: sample-microservice
spec:
  selector:
    app: sample-microservice
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  type: LoadBalancer
This YAML file can be applied using the "kubectl apply -f <filename>" command to create the Service in your Kubernetes cluster.

note: Remember to adjust the YAML file according to your specific requirements, such as the service name, labels, ports, and type. 

